import { Tabs } from "nextra/components";
import { Frame } from "@/components";
import { Steps } from 'nextra/components'
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import LlmAdapters from "@/snippets/llm-adapters.mdx";

# Self Hosting (Copilot Runtime)

The Copilot Runtime is the back-end component of CopilotKit, handling the communication with LLM, message history, state and more.

You may choose to self-host the Copilot Runtime, or [use Copilot Cloud](https://cloud.copilotkit.ai) (recommended).


## Integration

<Steps>
  ### Step 1: Create an Endpoint

  <SelfHostingCopilotRuntimeCreateEndpoint />

  ### Step 2: Configure the `<CopilotKit>` Provider

  <SelfHostingCopilotRuntimeConfigureCopilotKitProvider />

</Steps>

## LLM Adapters 
<LlmAdapters />


## Further Reading

- [`CopilotRuntime` Class Reference](/reference/classes/copilot-runtime/CopilotRuntime)
- [LLM Adapters](/reference/classes/CopilotRuntime/llm-adapters/OpenAIAdapter)

<Frame>
  <div className="w-full pb-4">
  ```mermaid
  sequenceDiagram
    participant core as @copilotkit/react-core
    participant runtime as Copilot Runtime
    participant llm as LLM

    core->>runtime: "Hey, my name is Uli."
    runtime->>llm: Request
    llm->>runtime: Response
    runtime->>core: "Hello Uli, how can I help you?"
  ```
  </div>
</Frame>
