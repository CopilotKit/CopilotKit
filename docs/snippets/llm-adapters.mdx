import { Callout } from "fumadocs-ui/components/callout";
import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import { FaCloud, FaServer } from "react-icons/fa";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";

CopilotKit uses `BuiltInAgent` to handle LLM communication. Simply specify the model you want to use with the
`"provider/model"` format, and CopilotKit handles provider initialization and API key management automatically.

Currently, we natively support the following providers:

- **OpenAI** - `"openai/gpt-4o"`, `"openai/gpt-4o-mini"`, `"openai/o3-mini"`, etc.
- **Anthropic (Claude)** - `"anthropic/claude-sonnet-4.5"`, `"anthropic/claude-opus-4"`, etc.
- **Google (Gemini)** - `"google/gemini-2.5-pro"`, `"google/gemini-2.5-flash"`, etc.

<Callout type="info">
  You can also pass any [Vercel AI SDK](https://sdk.vercel.ai/docs) `LanguageModel` instance directly to
  `BuiltInAgent` for providers not listed above. This gives you access to dozens of additional providers.
</Callout>

<TailoredContent id="hosting">
  <TailoredContentOption
    id="copilot-cloud"
    title="Copilot Cloud (Recommended)"
    description="Use our hosted backend endpoint to get started quickly."
    icon={<FaCloud />}
  >
  Configure the used LLM model [on your Copilot Cloud dashboard](https://cloud.copilotkit.ai/)!

  </TailoredContentOption>

  <TailoredContentOption
    id="self-hosted"
    title="Self-hosting"
    description="Learn to host CopilotKit's runtime yourself with your own backend."
    icon={<FaServer />}
  >

  <Steps>
    <Step>
    ## Find your CopilotRuntime instance
    <FindYourCopilotRuntime components={props.components} />

    </Step>

    <Step>
    ## Configure your BuiltInAgent model

    Update the `BuiltInAgent` in your CopilotRuntime to use your desired model:

    ```ts
    import { CopilotRuntime } from "@copilotkit/runtime";
    import { BuiltInAgent } from "@copilotkit/runtime/v2";

    const runtime = new CopilotRuntime({
      agents: {
        default: new BuiltInAgent({
          model: "openai/gpt-4o", // Change to your desired provider/model
        }),
      },
    });
    ```

    You can also configure additional options:

    ```ts
    import { CopilotRuntime } from "@copilotkit/runtime";
    import { BuiltInAgent } from "@copilotkit/runtime/v2";

    const runtime = new CopilotRuntime({
      agents: {
        default: new BuiltInAgent({
          model: "anthropic/claude-sonnet-4.5",
          temperature: 0.7,
          maxOutputTokens: 4096,
          prompt: "You are a helpful AI assistant.",
        }),
      },
    });
    ```

    </Step>

    <Step>
    ## Set your API key

    Make sure the appropriate environment variable is set for your provider:

    ```plaintext title=".env"
    # OpenAI
    OPENAI_API_KEY=your_key_here

    # Anthropic
    ANTHROPIC_API_KEY=your_key_here

    # Google
    GOOGLE_API_KEY=your_key_here
    ```

    Or pass the key directly:

    ```ts
    new BuiltInAgent({
      model: "openai/gpt-4o",
      apiKey: "sk-...",
    })
    ```
    </Step>

  </Steps>

  </TailoredContentOption>
</TailoredContent>
