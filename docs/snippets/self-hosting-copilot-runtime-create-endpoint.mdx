import { IoLogoVercel, IoLogoNodejs } from "react-icons/io5";
import { SiNestjs } from "react-icons/si";
import { RiNextjsLine } from "react-icons/ri";

The Copilot Runtime uses a `BuiltInAgent` to handle LLM communication. You simply specify which model to use
with the `"provider/model"` format, and CopilotKit takes care of the rest.

### Supported Providers

CopilotKit natively supports the following providers:

| Provider | Model Format | Environment Variable |
|----------|-------------|---------------------|
| OpenAI | `"openai/gpt-4o"` | `OPENAI_API_KEY` |
| Anthropic | `"anthropic/claude-sonnet-4.5"` | `ANTHROPIC_API_KEY` |
| Google Gemini | `"google/gemini-2.5-pro"` | `GOOGLE_API_KEY` |

<Callout type="info">
  You can use any model from these providers by specifying the provider prefix followed by the model name,
  e.g. `"openai/gpt-4o-mini"`, `"anthropic/claude-3.5-haiku"`, `"google/gemini-2.5-flash"`.
</Callout>

### Add your API key

Add the API key for your chosen provider to your `.env` file:

```plaintext title=".env"
# Choose one (or more) depending on your provider:
OPENAI_API_KEY=your_api_key_here
# ANTHROPIC_API_KEY=your_api_key_here
# GOOGLE_API_KEY=your_api_key_here
```

<Callout type="warn">
    Please note that some models (e.g. GPT-4o) require a paid API key. **If you are using a free OpenAI API key**, change the model to a different option such as `"openai/gpt-4o-mini"`.
</Callout>

### Setup the Runtime Endpoint

<Callout type="warn">
    ### Serverless Function Timeouts

    When deploying to serverless platforms (Vercel, AWS Lambda, etc.), be aware that default function timeouts may be too short for CopilotKit's streaming responses:

    - Vercel defaults: 10s (Hobby), 15s (Pro)
    - AWS Lambda default: 3s

    **Solution options:**
    1. Increase function timeout:
        ```json
        // vercel.json
        {
          "functions": {
            "api/copilotkit/**/*": {
              "maxDuration": 60
            }
          }
        }
        ```
    2. Use [Copilot Cloud](https://cloud.copilotkit.ai/) to avoid timeout issues entirely
</Callout>

<Tabs groupId="endpoint-type" items={[
    { value: 'Next.js App Router', icon: <RiNextjsLine className="text-xl" /> },
    { value: 'Next.js Pages Router', icon: <RiNextjsLine className="text-xl" /> },
    { value: 'Node.js Express', icon: <IoLogoNodejs className="text-xl" /> },
    { value: 'Node.js HTTP', icon: <IoLogoNodejs className="text-xl" /> },
    { value: 'NestJS', icon: <SiNestjs className="text-xl" /> }
]}>

    {/* Next.js App Router */}
    <Tab value="Next.js App Router">
        Create a new route to handle the `/api/copilotkit` endpoint.

        ```ts title="app/api/copilotkit/route.ts"
        import {
          CopilotRuntime,
          copilotRuntimeNextJSAppRouterEndpoint,
        } from '@copilotkit/runtime';
        import { BuiltInAgent } from '@copilotkit/runtime/v2';
        import { NextRequest } from 'next/server';

        const runtime = new CopilotRuntime({
          agents: {
            default: new BuiltInAgent({
              model: "openai/gpt-4o",
            }),
          },
        });

        export const POST = async (req: NextRequest) => {
          const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
            runtime,
            endpoint: '/api/copilotkit',
          });

          return handleRequest(req);
        };
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.
    </Tab>

    {/* Next.js Pages Router */}
    <Tab value="Next.js Pages Router">
        Create a new route to handle the `/api/copilotkit` endpoint:

        ```ts title="pages/api/copilotkit.ts"
        import { NextApiRequest, NextApiResponse } from 'next';
        import {
          CopilotRuntime,
          copilotRuntimeNextJSPagesRouterEndpoint,
        } from '@copilotkit/runtime';
        import { BuiltInAgent } from '@copilotkit/runtime/v2';

        const runtime = new CopilotRuntime({
          agents: {
            default: new BuiltInAgent({
              model: "openai/gpt-4o",
            }),
          },
        });

        const handler = async (req: NextApiRequest, res: NextApiResponse) => {
          const handleRequest = copilotRuntimeNextJSPagesRouterEndpoint({
            endpoint: '/api/copilotkit',
            runtime,
          });

          return await handleRequest(req, res);
        };

        export default handler;
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.
    </Tab>

    {/* Node.js Express */}
    <Tab value="Node.js Express">
        Create a new Express.js app and set up the Copilot Runtime handler:

        ```ts title="server.ts"
        import express from 'express';
        import {
          CopilotRuntime,
          copilotRuntimeNodeHttpEndpoint,
        } from '@copilotkit/runtime';
        import { BuiltInAgent } from '@copilotkit/runtime/v2';

        const app = express();

        app.use('/copilotkit', (req, res, next) => {
          (async () => {
            const runtime = new CopilotRuntime({
              agents: {
                default: new BuiltInAgent({
                  model: "openai/gpt-4o",
                }),
              },
            });
            const handler = copilotRuntimeNodeHttpEndpoint({
              endpoint: '/copilotkit',
              runtime,
            });

            return handler(req, res);
          })().catch(next);
        });

        app.listen(4000, () => {
          console.log('Listening at http://localhost:4000/copilotkit');
        });
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>

    {/* Node.js HTTP */}
    <Tab value="Node.js HTTP">
        Set up a simple Node.js HTTP server and use the Copilot Runtime to handle requests:

        ```ts title="server.ts"
        import { createServer } from 'node:http';
        import {
          CopilotRuntime,
          copilotRuntimeNodeHttpEndpoint,
        } from '@copilotkit/runtime';
        import { BuiltInAgent } from '@copilotkit/runtime/v2';

        const runtime = new CopilotRuntime({
          agents: {
            default: new BuiltInAgent({
              model: "openai/gpt-4o",
            }),
          },
        });

        const server = createServer((req, res) => {
          const handler = copilotRuntimeNodeHttpEndpoint({
            endpoint: '/copilotkit',
            runtime,
          });

          return handler(req, res);
        });

        server.listen(4000, () => {
          console.log('Listening at http://localhost:4000/copilotkit');
        });
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>

    {/* NestJS */}
    <Tab value="NestJS">
        Set up a controller in NestJS to handle the Copilot Runtime endpoint:

        ```ts title="copilotkit.controller.ts"
        import { All, Controller, Req, Res } from '@nestjs/common';
        import { CopilotRuntime, copilotRuntimeNestEndpoint } from '@copilotkit/runtime';
        import { BuiltInAgent } from '@copilotkit/runtime/v2';
        import { Request, Response } from 'express';

        @Controller()
        export class CopilotKitController {
          @All('/copilotkit')
          copilotkit(@Req() req: Request, @Res() res: Response) {
            const runtime = new CopilotRuntime({
              agents: {
                default: new BuiltInAgent({
                  model: "openai/gpt-4o",
                }),
              },
            });

            const handler = copilotRuntimeNestEndpoint({
              runtime,
              endpoint: '/copilotkit',
            });
            return handler(req, res);
          }
        }
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>
</Tabs>
