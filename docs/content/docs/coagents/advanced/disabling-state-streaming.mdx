---
title: "Disabling state streaming"
icon: "lucide/Cog"
description: "Granularly control what is streamed to the frontend."
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"

## What is this?
By default, CopilotKit will stream both your state and tool calls to the frontend.
You can disable this by using CopilotKit's custom `RunnableConfig`.

## When should I use this?

Occasionally, you'll want to disable streaming temporarily â€” for example, the LLM may be
doing something the current user should not see, like emitting tool calls or questions 
pertaining to other employees in an HR system.

## Implementation

### Disable all streaming
You can disable all message streaming and tool call streaming by passing `emit_messages=False` and `emit_tool_calls=False` to the CopilotKit config.

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python
        from copilotkit.langgraph import copilotkit_customize_config

        def frontend_actions_node(state: AgentState, config: RunnableConfig):
            
            # 1) Configure CopilotKit not to emit messages
            modifiedConfig = copilotkit_customize_config(
                config,
                emit_messages=False, # if you want to disable message streaming # [!code highlight]
                emit_tool_calls=False # if you want to disable tool call streaming # [!code highlight]
            )

            # 2) Provide the actions to the LLM
            model = ChatOpenAI(model="gpt-4o").bind(state.copilotkit.actions)

            # 3) Call the model with CopilotKit's modified config
            response = await model.ainvoke(*state, modifiedConfig)

            # don't return the new response to hide it from the user
            return state
        ```
    </Tab>
    <Tab value="TypeScript">
        ```typescript
        import { copilotkitCustomizeConfig } from '@copilotkit/sdk-js/langgraph';

        async function frontendActionsNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
            // 1) Configure CopilotKit not to emit messages
            const modifiedConfig = copilotkitCustomizeConfig(
                config,
                { emitMessages: false, emitToolCalls: false }
            );

            // 2) Provide the actions to the LLM
            const model = ChatOpenAI({ model: 'gpt-4o' }).bind(state.copilotkit.actions);

            // 3) Call the model with CopilotKit's modified config
            const response = await model.invoke(...state, modifiedConfig);

            // don't return the new response to hide it from the user
            return state
        }
        ```
    </Tab>
</Tabs>

### Enable streaming for specific tool calls
If you want to be more granular, you can enable streaming for specific tool calls which will only emit messages and tool calls for those tool calls.

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python
        from copilotkit.langgraph import copilotkit_customize_config

        def frontend_actions_node(state: AgentState, config: RunnableConfig):
            # [!code highlight:12]
            # 1) Configure CopilotKit to only emit tool calls for the SearchTool
            config = copilotkit_customize_config(
                config,
                emit_intermediate_state=[
                    {
                        "state_key": "steps",
                        "tool": "SearchTool",
                        "tool_argument": "steps"
                    },
                ]
            )

            # 2) Provide the actions to the LLM
            model = ChatOpenAI(model="gpt-4o").bind(state.copilotkit.actions)

            # 3) Call the model with CopilotKit's modified config
            response = await model.ainvoke(*state, modifiedConfig)

            # don't return the new response to hide it from the user
            return state
        ```
    </Tab>
    <Tab value="TypeScript">
        ```typescript
        import { copilotkitCustomizeConfig } from '@copilotkit/sdk-js/langgraph';

        async function frontendActionsNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
            // [!code highlight:12]
            // 1) Configure CopilotKit not to emit messages
            const modifiedConfig = copilotkitCustomizeConfig(
                config,
                emitIntermediateState=[
                    {
                        "stateKey": "steps",
                        "tool": "SearchTool",
                        "toolArgument": "steps",
                    },
                ],
            );

            // 2) Provide the actions to the LLM
            const model = ChatOpenAI({ model: 'gpt-4o' }).bind(state.copilotkit.actions);

            // 3) Call the model with CopilotKit's modified config
            const response = await model.invoke(...state, modifiedConfig);

            // don't return the new response to hide it from the user
            return state
        }
        ```
    </Tab>
</Tabs>

