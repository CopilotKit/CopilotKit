---
title: "Getting Started"
description: "Get started with CoAgents in just a few minutes."
icon: "lucide/Play"
---

import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import LLMAdapters from "@/snippets/llm-adapters.mdx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import FindCopilotRuntimeSnippet from "@/snippets/find-your-copilot-runtime.mdx";

## Before you start

At the moment CoAgents integrates with LangGraph-powered agents using **LangGraph-Python**. <br/>
(Support for LangGraph.js and LangGraph Cloud is coming very soon! [Contact us]() for early access).

**For orientation, here's how CoAgents are wired:**

<CoAgentsDiagram />

- In this tutorial, we'll hook up the 2 middle components:
  - **CopilotKit Runtime**
  - **Remote Endpoint (FastAPI + CopilotKit Python SDK)**

<Callout type="info">
  This guide assumes youâ€™re familiar with using LangGraph to build agent
  workflows. If you need a quick introduction, check out [this brief example
  from the LangGraph docs](https://langchain-ai.github.io/langgraph/).
</Callout>

## Getting started

<Steps>

<Step>

First, take a minute to **[go through the CopilotKit quickstart](/quickstart), and integrate CopilotKit into your React app.**
This should only take a minute.

</Step>

<Step>
  Then, setup a CopilotKit Remote-Endpoint using FastAPI. Follow the [Remote
  Endpoint quickstart](/guides/backend-actions/remote-backend-endpoint). <br />
  **This endpoint will serve your (Python) LangGraph agent.**
</Step>

<Step>

## Connect your FastAPI Remote Endpoint to a LangGraph agent

At this point you should have CopilotKit hooked into your application, connected to a FastAPI Remote Endpoint.

The next step is to configure the Remote Endpoint to serve LangGraph agents.

First, find your `CopilotKitSDK` instance in your Python Remote Endpoint (typically `server.py`). <br/>
**Then modify your `CopilotKitSDK` instance (setup in the previous step) to serve LangGraph agents:**

```python title="server.py"
from copilotkit import CopilotKitSDK, LangGraphAgent # [!code highlight]
from .agent import the_langraph_graph # Import your LangGraph agent; in this example, it's the variable named `the_langraph_graph` in ./agent.py # [!code highlight]
from copilotkit.integrations.fastapi import add_fastapi_endpoint
from copilotkit.langchain import copilotkit_messages_to_langchain # you only need this if you use Google Gemini in your LangGraph agent.
# ... other imports

app = FastAPI()

# ...

# Initialize the CopilotKit SDK
sdk = CopilotKitSDK(
  agents=[ # [!code highlight:10]
    LangGraphAgent(
      name="basic_agent",
      description="Agent that answers questions about the weather",
      graph=the_langraph_graph,
      # copilotkit_config={ # if you use Google Gemini, uncomment  this code (and import `copilotkit_messages_to_langchain`, see above)
      #  "convert_messages": copilotkit_messages_to_langchain(use_function_call=True)
      # }
    )
  ],
  # ...
)

# ...

# Add the CopilotKit endpoint to your FastAPI app
add_fastapi_endpoint(app, sdk, "/copilotkit_remote")

# ...

```

<Callout>
  Remember the name `basic_agent`, we'll need it as we move on to integrating
  this agent into the frontend.
</Callout>

### Are you using Google Gemini models?

Until there is full parity between Gemini and other models in the LangChain ecosystem, you'll need to uncomment the `copilotkit_config` section shown above when using Gemini models in your LangGraph agent.

</Step>

<Step>

## Agent-lock your Copilot to the `basic_agent` agent.

CopilotKit supports router-mode as well as agent-lock mode. For more detail see [router-mode / agent-mode](/coagents/advanced/router-mode-agent-lock).
In short: agent-lock modes locks your Copilot to a single LangGraph agent;
router-mode automatically routes requests to the right agent based on the user's context and query.

**For simplicity, we'll use agent-lock mode in these tutorials,** but we encourage you to explore router-mode in your production use-cases to support more complex agent workflows.

Lock the Copilot to the `basic_agent` setup earlier. This means every single interaction with the Copilot will be forwarded to the locked agent.

```tsx filename="src/page.tsx"
// The Copilot will now invoke the LangGraph agent directly, not the Copilot router.
<CopilotKit
  runtimeUrl="/api/copilotkit"
  agent="basic_agent" // agent-lock the Copilot, see 'agent-lock vs router-mode' // [!code highlight]
>
  {...}
</CopilotKit>
```

</Step>
</Steps>

ðŸŽ‰ Congrats! You've successfully integrated a LangGraph agent chatbot to your application!
Give it a try by writing text in the chatbot UI and pressing send.
You are now chatting with a LangGraph agent!

<Frame className="my-6">
  <img
    src="/images/coagents/CoAgents-ChatHello.gif"
    alt="CoAgents Chat Hello demonstration"
    className="w-2/3 mx-auto"
  />
</Frame>

<CoAgentsEnterpriseCTA />
