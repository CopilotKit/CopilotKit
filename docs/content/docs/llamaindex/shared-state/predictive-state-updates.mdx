---
title: "Predictive state updates"
icon: "lucide/Podcast"
description: Stream in-progress agent state updates to the frontend.
---
import { IframeSwitcher } from "@/components/content"
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content.tsx";
import { FaWrench } from "react-icons/fa";
import { FaArrowUp } from "react-icons/fa";

<IframeSwitcher
  id="predictive-state-updates-example"
  exampleUrl="https://feature-viewer.copilotkit.ai/langgraph/feature/predictive_state_updates?sidebar=false&chatDefaultOpen=false"
  codeUrl="https://feature-viewer.copilotkit.ai/langgraph/feature/predictive_state_updates?view=code&sidebar=false&codeLayout=tabs"
  exampleLabel="Demo"
  codeLabel="Code"
  height="700px"
/>

<Callout type="info">
  This example demonstrates predictive state updates in the [CopilotKit Feature Viewer](https://feature-viewer.copilotkit.ai/langgraph/feature/predictive_state_updates).
</Callout>

## What is this?

A LlamaIndex agent's state updates discontinuously; only when state changes are explicitly made.
But even a _single operation_ often takes many seconds to run and contains sub-steps of interest to the user.

**Agent-native applications** reflect to the end-user what the agent is doing **as continuously as possible.**

CopilotKit enables this through its concept of **_predictive state updates_**.

## When should I use this?

Use predictive state updates when you want to:
- **Keep users engaged** by avoiding long loading indicators
- **Build trust** by demonstrating what the agent is working on
- Enable **agent steering** - allowing users to course-correct the agent if needed

## Important Note

When your agent finishes executing, **its final state becomes the single source of truth**. While intermediate state updates are great for real-time feedback, any changes you want to persist must be explicitly included in the final state. Otherwise, they will be overwritten when the operation completes.

## Implementation

<Steps>
  <Step>
    ### Define the state
    We'll be defining an `observed_steps` field in the state, which will be updated as the agent performs different steps of a task.

    ```python title="agent.py"
    from typing import List
    from llama_index.llms.openai import OpenAI
    from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
    from fastapi import FastAPI

    # Define initial state with observed_steps
    initial_state = {
        "observed_steps": []
    }
    ```
  </Step>
  <Step>
    ### Emit the intermediate state

    <TailoredContent
        id="state-emission"
        header={
            <div>
                <p className="text-xl font-semibold">How would you like to emit state updates?</p>
                <p className="text-base">
                    You can either manually emit state updates or configure specific tool calls to emit updates.
                </p>
            </div>
        }
    >
        <TailoredContentOption
            id="tool-emission"
            title="Tool-Based Predictive State Updates"
            description="Configure specific tool calls to automatically emit intermediate state updates."
            icon={<FaWrench />}
        >
            For long-running tasks, you can create a tool that updates state and emits it to the frontend. In this example, we'll create a step progress tool that the LLM calls to report its progress.

            ```python title="agent.py"
            from typing import Annotated, List
            from llama_index.llms.openai import OpenAI
            from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
            from llama_index.protocols.ag_ui.events import StateSnapshotWorkflowEvent
            from llama_index.core.workflow import Context
            from fastapi import FastAPI


            async def step_progress(
                ctx: Context,
                steps: Annotated[List[str], "The list of steps completed so far."]
            ) -> str:
                """Reports the current progress steps to keep the user informed.

                Args:
                    ctx: The workflow context for accessing and updating state.
                    steps: The list of steps completed so far.

                Returns:
                    str: A message indicating the progress was received.
                """
                # Update state with the new steps
                state = await ctx.get("state", default={})
                state["observed_steps"] = steps
                await ctx.set("state", state)
                
                # Emit state snapshot to frontend
                ctx.send_event(StateSnapshotWorkflowEvent(snapshot=state))
                
                return "Progress received."


            agentic_chat_router = get_ag_ui_workflow_router(
                llm=OpenAI(model="gpt-4o"),
                system_prompt="""
                You are a task performer. When given a task, break it down into steps
                and report your progress using the step_progress tool after completing each step.
                """,
                backend_tools=[step_progress],
                initial_state={
                    "observed_steps": [],
                },
            )

            app = FastAPI()
            app.include_router(agentic_chat_router)

            if __name__ == "__main__":
                import uvicorn
                uvicorn.run(app, host="0.0.0.0", port=8000)
            ```

            <Callout>
              With this configuration, the agent emits state updates each time it calls the `step_progress` tool, giving the frontend real-time visibility into progress.
            </Callout>
        </TailoredContentOption>
    </TailoredContent>
  </Step>
  <Step>
    ### Observe the predictions
    These predictions will be emitted as the agent runs, allowing you to track its progress before the final state is determined.

    ```tsx title="ui/app/page.tsx"
    "use client";
    
    import { useCoAgent, useCoAgentStateRender } from '@copilotkit/react-core';

    // ...
    type AgentState = {
        observed_steps: string[];
    };

    const YourMainContent = () => {
        // Get access to both predicted and final states
        const { state } = useCoAgent<AgentState>({ name: "my_agent" });

        // Add a state renderer to observe predictions
        useCoAgentStateRender({
            name: "my_agent",
            render: ({ state }) => {
                if (!state.observed_steps?.length) return null;
                return (
                    <div>
                        <h3>Current Progress:</h3>
                        <ul>
                            {state.observed_steps.map((step, i) => (
                                <li key={i}>{step}</li>
                            ))}
                        </ul>
                    </div>
                );
            },
        });

        return (
            <div>
                <h1>Agent Progress</h1>
                {state.observed_steps?.length > 0 && (
                    <div>
                        <h3>Final Steps:</h3>
                        <ul>
                            {state.observed_steps.map((step, i) => (
                                <li key={i}>{step}</li>
                            ))}
                        </ul>
                    </div>
                )}
            </div>
        )
    }
    ```

    <Callout type="warn" title="Important">
      The `name` parameter must exactly match the agent name you defined in your CopilotRuntime configuration (e.g., `my_agent` from the quickstart).
    </Callout>
  </Step>
  <Step>
    ### Give it a try!
    Now you'll notice that the state predictions are emitted as the agent makes progress, giving you insight into its work before the final state is determined.
    You can apply this pattern to any long-running task in your agent.
  </Step>
</Steps>

