---
title: Tool-based
description: Learn how to implement Human-in-the-Loop (HITL) using LlamaIndex Agents.
icon: lucide/Share2
---

import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";
import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/coagents/node-hitl.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

<Callout type="info">
  Pictured above is the [llamaindex
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/llamaindex/starter)
  with the implementation below applied!
</Callout>

## What is this?


CopilotKit lets you to add custom UI to take user input and then pass it back to the agent upon completion.

## Why should I use this?

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

## Implementation

<Steps>
    <Step>
        ### Run and connect your agent

        You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
        you can follow the instructions in the [Getting Started](/llamaindex/quickstart/llamaindex) guide.

        If you don't already have an agent, you can use the [llamaindex starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/llamaindex/starter) as a starting point
        as this guide uses it as a starting point.
    </Step>

    <Step>
      ### Install the CopilotKit SDK
      <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Add a tool to your agent
        Add a tool to your agent that will be used to write an essay. Since the tool will be used in the frontend,
        we'll add it to the `frontend_tools` list.

        ```python title="agent-py/agent/agent.py"
        from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
        from llama_index.llms.openai import OpenAI
        from fastapi import FastAPI

        def write_essay(draft: str) -> str:
            """Writes an essay and takes the draft as an argument."""
            return "Essay draft written!"

        app = FastAPI()

        router = get_ag_ui_workflow_router(
            llm=OpenAI(model="gpt-4.1"),
            frontend_tools=[write_essay],
        )

        app.include_router(router)

        if __name__ == "__main__":
            import uvicorn
            uvicorn.run(app, host="0.0.0.0", port=8000)
        ```
    </Step>

    <Step>
        ### Add a `useCopilotAction` to your Frontend
        First, we'll create a component that renders the agent's essay draft and waits for user approval.

        ```tsx title="ui/app/page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core"
        import { Markdown } from "@copilotkit/react-ui"

        function YourMainContent() {
          // ...

          useCopilotAction({
            name: "writeEssay",
            available: "remote",
            description: "Writes an essay and takes the draft as an argument.",
            parameters: [
              { name: "draft", type: "string", description: "The draft of the essay", required: true },
            ],
            // [!code highlight:25]
            renderAndWaitForResponse: ({ args, respond, status }) => {
              return (
                <div>
                  <Markdown content={args.draft || 'Preparing your draft...'} />

                  <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
                    <button
                      onClick={() => respond?.("CANCEL")}
                      disabled={status !== "executing"}
                      className="border p-2 rounded-xl w-full"
                    >
                      Try Again
                    </button>
                    <button
                      onClick={() => respond?.("SEND")}
                      disabled={status !== "executing"}
                      className="bg-blue-500 text-white p-2 rounded-xl w-full"
                    >
                      Approve Draft
                    </button>
                  </div>
                </div>
              );
            },
          });

          // ...
        }
        ```
    </Step>

    <Step>
    ### Setup the LlamaIndex Agent
    On the agent side, we are already done! LlamaIndex natively supports the AG-UI protocol and will automatically
    pass control back to the frontend when the `writeEssay` action is found in the model's response.
    </Step>
    
    <Step>
        ### Give it a try!
        Try asking your agent to write an essay about the benefits of AI. You'll see that it will generate an essay,
        stream the progress and eventually ask you to review it.
    </Step>

</Steps>