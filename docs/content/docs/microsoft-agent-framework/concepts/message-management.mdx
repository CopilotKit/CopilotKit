---
title: Message flow
icon: lucide/MessageCircle
---

Message management in agents operates with CopilotKit as the "ground truth" for the full chat session. 
When an agent session begins, it receives the existing CopilotKit chat history to maintain conversational
continuity across different agents.

<Callout>
While all of this information is great to know, in most cases you won't need to worry about these details to
build rich agentic applications. Use the information here as a reference when getting really deep into 
the agent internals.
</Callout>

### Can I modify the message history?

You can modify the message history from agent framework by using the `RemoveMessage` class. For example to remove all messages from the chat history: 

```python
from agent_core.messages import RemoveMessage

def a_node(state: AgentState, config):
    # ...
    return {"messages":  [RemoveMessage(id=m.id) for m in state['messages']]}
```

See the [agent framework documentation](https://agent-ai.github.io/agent framework/how-tos/memory/delete-messages/) for more information.

<Callout>
Editing the message history is not currently supported on the front-end, but will be soon.
</Callout>

### Can I persist chat history?

Yes! There are a few ways to persist various portions of a chat's history:
- [Threads](/microsoft-agent-framework/persistence/threads)
- [Message Persistence](/microsoft-agent-framework/persistence/message-persistence)
- [Agent State](/microsoft-agent-framework/persistence/loading-agent-state)

## Types of LLM Messages

Modern LLM interactions produce two distinct types of messages:

1. **Communication Messages**: Direct responses and interactions with users
2. **Internal Messages**: Agent "thoughts" and reasoning processes

A well known example of this pattern is OpenAI's o1 model, which has sophisticated reasoning capabilities and thoughts. Its internal
thought processes are presented distinctly from 'communication messages' which are clearly visible to the end-user.

agent framework agents can operate similarly. An LLM call's output can be considered either a communication message, or an internal message.

### Emitting Messages for long running tasks

Sometimes you'll have a task that is running for a long time, and you want the user to be aware of what's happening. By default, agent framework does not support this, because messages are only emitted on node transitions. However, CopilotKit allows you to accomplish this by using the `copilotkit_emit_message` function.

```python
async def ask_name_node(state: GreetAgentState, config: RunnableConfig):
    """
    Ask the user for their name.
    """

    content = "Hey, what is your name? ðŸ™‚"
 
    await copilotkit_emit_message(config, content)

    # something long running here...
 
    return {
        "messages": AIMessage(content=content),
    }
```

Want some more help managing messages in your agent application? Check out our guide on [emitting messages](/microsoft-agent-framework/advanced/emit-messages).

## Message Flow
Messages flow between CopilotKit and agent framework in a specific way:

- All messages from agent framework are forwarded to CopilotKit
- On a fresh agent invocation, the full CopilotKit chat history is provided to the agent framework agent as its pre-existing chat history.

When a agent completes its execution, its relevant messages become part of CopilotKit's persistent chat history. This allows for all future agent invocations to get context from the full chat history.
